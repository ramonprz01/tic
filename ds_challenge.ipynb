{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1cb72b-90ba-4bce-adb2-5a756034064f",
   "metadata": {},
   "source": [
    "# The Iconic Data Science Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678832f3-673c-4eea-bbe8-b85659890a6e",
   "metadata": {},
   "source": [
    "![the_iconic](https://www.lifehacker.com.au/coupons/vfiles/55-27fd5e0f09d2a4389c956496f4e35a6b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47fac34-d43f-430d-9831-c7e60966da26",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1faaa-2c02-48d8-a9f9-9e293f832474",
   "metadata": {},
   "source": [
    "1. Scenario\n",
    "2. Data Inspection\n",
    "3. Data Cleaning\n",
    "4. Feature Engineering\n",
    "5. Feature Selection\n",
    "6. Gender Inference\n",
    "7. Gender Classification\n",
    "8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5096f7-3578-41ed-8ef6-cd4cb101e41f",
   "metadata": {},
   "source": [
    "## 01 Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd91789-12b6-4493-9b32-e0176fb31546",
   "metadata": {},
   "source": [
    "The Iconic collects a lot of useful information from its users while respecting their privacy. Because of this though, gender is not explicitely asked from its customers but rather inferred with algorithms or by incentivizing customers to provide such information. The motivation for wanting this piece of information is clear, in order to provide consumers with the best experience possible, and to put in from of them most relevant items possible, this piece of information makes such a task a much easier one.\n",
    "\n",
    "In this notebook I tackle 5 tasks using data from customers at The Iconic, data cleaning, feature engineering, feature selection, gender inference and classification. The main goal of this notebook is to provide a document that takes its user from data cleaning to prediction rather that a system for internal use that could go into production, those steps steps are different and thus not emphazised in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446296a2-183a-48f0-813e-d10a8b02983d",
   "metadata": {},
   "source": [
    "## 02 Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8f9f1-0720-4e9d-9499-235093a237f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, json, time\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import umap\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6324a6-77ff-4235-915b-b8dc41ab7816",
   "metadata": {},
   "source": [
    "The data provided comes in JSON format and thus, we will read it line by line, add it to a list, and create our dataframe from that list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549026e-9311-472c-8627-10006beb4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "file = os.path.join(path, 'raw', 'data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e52e5-1bce-47dd-ae2e-0653d3be662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for line in open(file, 'r'):\n",
    "    data_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ec84d-107d-41d0-92a5-149e7d842995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322dc06-06a1-4e9e-b0da-f5302f37a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f35da-6855-4ea0-8640-7d58c2cf7014",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77c583-9697-4bf2-aa31-6ac24b3b4ae1",
   "metadata": {},
   "source": [
    "Check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79f9f2-0ee4-4167-946f-ebcd9d2514c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12683d-3a3b-4d78-9784-8bab6148770d",
   "metadata": {},
   "source": [
    "Check if individual items add up to the items variables, if so, these will likely be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6571e-314c-400c-970d-473aac0eb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df['female_items'] + df['male_items'] + df['unisex_items'] - df['items']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34eb3b-8c9a-4530-944d-2aa295cf3e11",
   "metadata": {},
   "source": [
    "Inspect the unique values of all features. Go through each one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c7b4b-3458-40c4-9edc-ee3e5e82082c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     print(col)\n",
    "#     print(f\"Unique # of values: {df[col].nunique()}\")\n",
    "#     print(df[col].unique())\n",
    "#     print()\n",
    "#     print('-' * 50)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aef067-8017-4d52-8f32-aa5a66890652",
   "metadata": {},
   "source": [
    "Is the `sacc_items` variable unique or is it related to the gender sports variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd4004-608f-4f3c-a7cb-6d1fe4bb55c0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.sacc_items.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5bf75e-a407-4660-b29d-6f13b1196e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.mspt_items + df.wspt_items - df.sacc_items).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e135a-4020-4196-97a5-0d16d596f450",
   "metadata": {},
   "source": [
    "Are there a lot of work orders or can this variable be recoded as a dummy that says if the customer has order an item to their work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0066545c-39ba-404b-ba11-e7120f096bff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.work_orders.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c027885-0b54-4906-8fa4-28b43b79f369",
   "metadata": {},
   "source": [
    "Do all gender items add up to the items column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681f4c4-9696-4593-a6a4-f83060335228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.female_items + df.male_items + df.unisex_items - df['items']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be8d90-0c08-4f09-baf5-34c240071a60",
   "metadata": {},
   "source": [
    "Is there a particular order type or payment that dominates all transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a80e9c-3b4d-4a56-b460-d8a61719380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.cc_payments.sum() + df.afterpay_payments.sum() + df.paypal_payments.sum() + df.apple_payments.sum() - df['orders'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf945fe5-0db3-4156-9f97-4e59d5f4b797",
   "metadata": {},
   "source": [
    "Let's look at the distinction between payments and orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19efce-444c-4559-8dab-3d260d40e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payments = (df.cc_payments + df.afterpay_payments + df.paypal_payments + df.apple_payments)\n",
    "# orders = (df.msite_orders + df.desktop_orders + df.android_orders + df.ios_orders + df.other_device_orders)\n",
    "# how_orders = (df.work_orders + df.home_orders + df.parcelpoint_orders + df.other_collection_orders)\n",
    "# all_orders = pd.concat([payments, orders, how_orders], axis=1)\n",
    "# all_orders.columns = ['payments', 'orders', 'how_orders']\n",
    "# all_orders.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60effc69-0e92-412b-8c52-0201573e1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (all_orders.iloc[:, 1] - all_orders.iloc[:, 2]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc1c56-bb03-4425-b2ed-cf108152f8d9",
   "metadata": {},
   "source": [
    "Examine the footware variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd731259-4e36-47e5-9a1c-e699a21f29c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.wftw_items.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480910c0-e7df-4e4a-8605-e994063e1cc1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.mftw_items.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05b6a2-644a-4fd5-95b6-b24c312fc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.wftw_items.sum() / (df.mftw_items.sum() + df.wftw_items.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e7e12-db61-46e1-9da9-e9736bfcf915",
   "metadata": {},
   "source": [
    "It seems like women order more shoes than man.\n",
    "\n",
    "Let's look at the apparel now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25d760-6d7a-4177-af47-532dced219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.wapp_items.sum() / (df.mapp_items.sum() + df.wapp_items.sum())).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04a4ab-9e80-4ce6-bc28-776feb0436c1",
   "metadata": {},
   "source": [
    "Are Curvy Items a common purchase? Does the variable need to be rocoded to be a better predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac06d25-6ba2-49ab-ad35-be1954e0032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.curvy_items.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250544d-561c-42d8-b84f-465654a35845",
   "metadata": {},
   "source": [
    "Barely any curvy items purchase. Nonetheless, the few that have been purchase might provide a good signal in a dummy variable towards our end goal.\n",
    "\n",
    "Do people cancel often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93280ff-21a7-48ee-9dc3-36b609ed92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.cancels.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d182d-9f36-4b22-af27-ee6f094d5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.loc[df.cancels == 0, 'revenue'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e7924-4ece-4269-bb8a-a3ef3c3a72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.loc[df.revenue == 0, 'cancels'] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965885ce-51b8-4dc2-8099-fd793ceab84f",
   "metadata": {},
   "source": [
    "Barely any cancellations. This variable might be more useful as a dummy rather than a continous one.\n",
    "\n",
    "Returns could provide a good indicator as to which gender is buying and returning items, but because of the skewness of this variable, we might be better served by creating a dummy for it called, `has_returned_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74da509-41c4-4bf8-bbf4-779dfb89d9f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ed981-03e4-4bcf-bf92-b1639e497ce1",
   "metadata": {},
   "source": [
    "Vouchers are important and may incentivize customers to purchase more items when they are about to use the voucher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f6f30-8b09-462c-aa59-e930ff92d45c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.vouchers.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827c11e-09e5-4b90-8cdf-14fb91210024",
   "metadata": {},
   "source": [
    "Let's check Shipping Addresses and devices for any inconsistencies or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342a4d8-6c07-4ed2-9a83-f2d6a143fb9c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.shipping_addresses.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a2c2d-7ae2-440f-a906-8c0ae45e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.devices.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d9ffe-933e-4618-9141-c5862afe90bf",
   "metadata": {},
   "source": [
    "Devices might be more useful as a categorical variable with for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755522c4-6b8a-4499-abb8-47d697f6b0a4",
   "metadata": {},
   "source": [
    "Diff addresses is already a binary variable so we will keep it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd936f65-c66b-439f-a52f-a0500fa3b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.different_addresses.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e674ab0-c836-49db-80e4-8d9bc13f8e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b946b375-c9c7-4872-ab3d-268482a86391",
   "metadata": {},
   "source": [
    "Let's examine the `days_since_first_order` variable which seemed a bit odd at first glance when evaliating the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17881163-6a12-441b-aca7-6a1c5a99aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df['days_since_first_order'] < df['days_since_last_order']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49396ee0-58a8-43fb-89dc-d1237d3cc9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['days_since_first_order', 'days_since_last_order']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52239d80-448d-47ee-ae4d-b898d4f08029",
   "metadata": {},
   "source": [
    "The variable seems to be in the wrong unit. It doesn't seem plausible that a client made its first purchase 80+ years ago while The Iconic has been in business for much less than that. Let's check different time units such as minutes or hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c807a5-9885-4ddb-a965-01f197fdb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df['days_since_last_order'] / 24).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000642f-56e7-4ded-9c5e-0b00d1d14c3d",
   "metadata": {},
   "source": [
    "Dviding by 24 hours seem to be the best course of action here.\n",
    "\n",
    "`average_discount_used` seems higher than revenue in some instances, could it be due to a discount offer or a voucher used by the customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2010f2-3713-4123-a6b5-377903eb921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['average_discount_used', 'average_discount_onoffer', 'revenue']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52392e-f958-4edf-bfc5-6ce861145e9b",
   "metadata": {},
   "source": [
    "Let's looks at the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8af68e-5f87-412e-b335-695d2b4e8c62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.isna().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf14e6-286f-429f-9ad1-c7fe87c3c1d5",
   "metadata": {},
   "source": [
    "`coupon_discount_applied` has a few missing values but we can't just drop these rows. Let's examine the revenue made from and female items sold to all of our customers where this variable is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c9013-c03f-4501-88fd-c989aa3b838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(df['coupon_discount_applied'].isna())[['female_items', 'revenue']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe25fa-39c3-4831-a923-0468a2d14891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(df['coupon_discount_applied'].isna())['revenue'].mean().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632d425-265a-4a6e-9cc0-fef229f1e036",
   "metadata": {},
   "source": [
    "In addition to `coupon_discount_applied`, `redpen_discount_used` was not in the dictionary providedd. Let's examine them alongside the other coupon vars to see if we get a better idea as to what might be happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88c321-cc96-4e10-8dbf-5d3c307c6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.coupon_discount_applied.notna(), ['orders', 'redpen_discount_used', 'revenue', \n",
    "#                                             'average_discount_onoffer', 'average_discount_used', 'coupon_discount_applied']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25c7b6-e764-45ad-a2bd-56ea49abab2e",
   "metadata": {},
   "source": [
    "Finally let's look at the correlation Matrix of our numerical variables to see which vars are highly correlated with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128378b-3247-481c-ade0-89f15bbe2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_cols = [i for i in df.columns if str(df[i].dtype) != 'object']\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# # take out the annotate parameter to see only the colors\n",
    "# sns.heatmap(df[numerical_cols].corr(), annot=True, fmt=\".1f\", cmap='viridis')\n",
    "# # plt.xticks(rotation=75) # uncomment this to rotate the x axis\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704195e-1607-4cb8-aa4e-5013cbf840cd",
   "metadata": {},
   "source": [
    "After some thorough inspection of the data, here are some of the common issues that need to be fixed.\n",
    "\n",
    "Cleaning Tasks\n",
    "\n",
    "1. There were 249 duplicates in the dataset by all variables and by the customer id alone. These will be removed.\n",
    "2. The dataset contains additional variables that were not in the dictionary provided, namely, `coupon_discount_applied` and `redpen_discount_used`. The latter does not add up completely to the `avg_discount_onoffer` or the discount used, nor does it match the proportional discount of the former. Until further investigation of the data generating process for these two, both will be dropped or ignored in the feature engineering and modeling phases.\n",
    "4. The column `days_since_last_order` needs to be either removed as it says that some clients have taken 90+ years to make an order or, it seems that adjusting it from hours to days (divide by 24) brings it to a reasonable level.\n",
    "5. The variable containing the average discount used seems to contain percentage rather than such large numbers. In many instances, this value is much larger than the revenue. Dividing this variable by 10,000 brings it down to a percentage that follows closely discount on offer. As this makes the most sense, the `average_discount_used` variable will be divided by 10,000.\n",
    "\n",
    "Feature engineering tasks\n",
    "\n",
    "1. The \"is newsletter subscriber\" column is the only categorical variable that is not numerical and it will be encoded as a dummy variable.\n",
    "2. Sports accessories is independent from the womens and men sport items. It will be converted into a dummy for those who purchased an accessory and those who didn't.\n",
    "3. Sports, footware, apparel and regular items will all be split into a variable representing the percentage of the gender the item purchased belong to.\n",
    "4. Work orders will become a dummy variable and all orders will be reduced to a percentable of home versus other.\n",
    "5. Destop order will be represented as a percentage against all other orders of that kind.\n",
    "6. Curvy items could add some signal towards gender but its proportion is quite low. Because of this, it will be converted into a dummy.\n",
    "7. Cancellations will be represented by the dummy `has_cancelled`.\n",
    "8. Devices will be represented as a binary variable called `multiple_devices`.\n",
    "9. Days as a customer will be represented as average days between purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1899872-52eb-474d-9152-0aa70e050ac2",
   "metadata": {},
   "source": [
    "## 04 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5e698-1675-4eeb-bbbc-06cd0e687bea",
   "metadata": {},
   "source": [
    "Get rid of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb564cf-c01c-4d8a-93b2-282c696817d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62c6ae-cb2b-44a4-91e8-4a05c2485dc4",
   "metadata": {},
   "source": [
    "Recode `days_since_last_order`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8d497-b0a8-4f7b-8212-9e459702df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_since_last_order'] = (df['days_since_last_order'] / 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d972f42-6d6d-426a-b0e2-d503b9ea01e7",
   "metadata": {},
   "source": [
    "Divide by `average_discount_used` by 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fd6a4-5e56-440f-bdd7-4effb28aa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_discount_used'] = (df['average_discount_used'] / 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8313e3-e950-42e2-ba66-864731649fc1",
   "metadata": {},
   "source": [
    "More than half of the missing values are missing where there is no coupon on offer or available. In addition, the variable is highly skewed and since the median and the mode are the same we will use these 2 to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c5b9e-3137-4e46-b21d-568d4b835546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coupon_discount_applied'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cde687-a8b9-4aa1-a048-3c09051fc223",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9713dd-581d-46ff-955c-3cb5aeec43b6",
   "metadata": {},
   "source": [
    "Let's save the cleaned dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673a069-0bcf-458b-923a-5c422c7fc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path, 'clean', 'clean_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde5b66-10b6-4da2-a35a-e6ab0be029ea",
   "metadata": {},
   "source": [
    "## 05 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f92c82-8039-40ad-aba1-4a174f9992bc",
   "metadata": {},
   "source": [
    "We will first create all of the binary variables previously discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722eaef-c40f-4dd6-a7b3-4dd97b88561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['is_newsletter_subscriber'], drop_first=True)\n",
    "df['curvy_item_dummy'] = df.curvy_items > 0\n",
    "df['work_order_dummy'] = df.work_orders > 0\n",
    "df['has_cancelled'] = df.cancels > 0\n",
    "df['multiple_devices'] = df.devices > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50146a-d11b-4542-9f88-965cbd588563",
   "metadata": {},
   "source": [
    "Let's now create a function to help us create the percentage columns for the items and orders placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668ecc1-b6f7-41b4-8a3b-03be319f2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pct(data, col, cols_to_add):\n",
    "    df_temp = data.copy()\n",
    "    df_temp['pct_' + col] = (df_temp[col] / df_temp[cols_to_add].sum(axis=1))\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc2568-6b57-4c08-bb2b-a01db235fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_pct(df, 'female_items', ['male_items', 'female_items', 'unisex_items'])\n",
    "df = get_pct(df, 'wapp_items', ['wapp_items', 'mapp_items'])\n",
    "df = get_pct(df, 'wacc_items', ['wacc_items', 'macc_items'])\n",
    "df = get_pct(df, 'wspt_items', ['wspt_items', 'mspt_items'])\n",
    "df = get_pct(df, 'cc_payments', ['cc_payments', 'paypal_payments', 'afterpay_payments', 'apple_payments'])\n",
    "df = get_pct(df, 'desktop_orders', ['msite_orders', 'desktop_orders', 'android_orders', 'ios_orders', 'other_device_orders'])\n",
    "df = get_pct(df, 'home_orders', ['home_orders', 'work_orders', 'parcelpoint_orders', 'other_collection_orders'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4d0c6-a402-4311-8f86-fa7e5e65bcc6",
   "metadata": {},
   "source": [
    "To create the average days between orders, we will subtract the first from last order, and then divide by all orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd2123-8ec3-477d-80c8-630243861524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_days_to_purcahse'] = ((df.days_since_first_order  - df.days_since_last_order) / df.orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea507c-bd6e-454d-a618-9f4b658152bf",
   "metadata": {},
   "source": [
    "Some items will have been divided by 0 and are now represented as NaN. we will fill these up with 0 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2c863-8651-4489-82c6-6daa9cdf0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8e2df-6d3c-4fc7-a96b-e8248b843a5a",
   "metadata": {},
   "source": [
    "## 06 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403a85d-9dca-4e76-9d16-0231dd0ed10e",
   "metadata": {},
   "source": [
    "Since we will first cluster the data into groups that make sense to use in place of gender, we will not use a regularazation method here to tell us which ones to pick. We will pick the ones identified above through the analysis and the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5af619-0a2b-4628-9562-4b59373a2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['orders', 'revenue', 'returns', 'vouchers', 'average_discount_used',\n",
    "                  'shipping_addresses', 'unisex_items', 'other_device_orders',\n",
    "                  'average_discount_onoffer', 'pct_female_items', 'pct_wapp_items',\n",
    "                  'pct_wacc_items', 'pct_wspt_items', 'pct_cc_payments',\n",
    "                  'pct_desktop_orders', 'pct_home_orders', 'avg_days_to_purcahse']\n",
    "\n",
    "cat_cols =  ['is_newsletter_subscriber_Y', 'curvy_item_dummy', 'different_addresses', 'work_order_dummy', 'has_cancelled', 'multiple_devices']\n",
    "\n",
    "all_cols = numerical_cols + cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9168f8-88d4-4df9-a4b3-0eafa731daa5",
   "metadata": {},
   "source": [
    "## 07 Gender Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59290480-9446-498b-8334-304904487f6e",
   "metadata": {},
   "source": [
    "We will infer gender with an usupervised algorithm, k-means, and using only the numerical variables. We will do so by\n",
    "\n",
    "1. Scaling the features by subtracting the mean and dividing by the standard deviation. Note that this assumes that the underlying distribution of our numerical vars is normal.\n",
    "2. Reduce the dimensions to 2 with UMAP (short for universal manifolm approximation and projection.\n",
    "3. Custer our 2 dimensions into 2 clusters, males and females, using k-means.\n",
    "4. Evalueate our result with the silhouette score for our predicted labels.\n",
    "\n",
    "Note that kmeans assumes that the shape of the data is spherical and thus, it draws a circle a s best as it can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776748e-fae0-479d-be50-851a9f2a61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('umap', umap.UMAP(n_neighbors=40, n_components=2, metric='manhattan', unique=False, random_state=42))\n",
    "])\n",
    "model = Pipeline([('km', KMeans(n_clusters=2, n_init=50, max_iter=500, random_state=42))])\n",
    "\n",
    "pipe = Pipeline([('preprocessing', preprocessing), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b71c39-8501-4cdc-aa3f-8616798cc517",
   "metadata": {},
   "source": [
    "Note, it will take about a minute for the pipeline to finish fitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe1f41-4adf-4603-a819-0d0fd7e74f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipe.fit(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c9886-cfd7-42f0-bf4c-bea97ea963b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "preprocessed_data = pipe[\"preprocessing\"].transform(df[numerical_cols])\n",
    "\n",
    "preds = pipe[\"model\"][\"km\"].labels_\n",
    "\n",
    "silhouette_score(preprocessed_data, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717f86b-cce2-4120-981f-8e6ebbfeffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(preds).value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1e76b-1ba3-42c2-9db8-aaee3d4c85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(preprocessed_data[:, 0], preprocessed_data[:, 1], c=preds, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a676ad-05da-4071-ae1d-0da3a44f3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc62491-0325-4770-b433-83a180361d8d",
   "metadata": {},
   "source": [
    "## 08 Gender Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239d4d6-e988-4880-ba54-dcf245ce1e71",
   "metadata": {},
   "source": [
    "Let's now get to classifying the gender. We will start by splitting the dataset into training and test set while specifying that our target variable requires stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b8398-389a-4cd8-9597-a2298965740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, all_cols].copy(), df['gender'].copy(), random_state=42, stratify=df['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15f707-df97-41f8-b703-7ade908fa325",
   "metadata": {},
   "source": [
    "Instantiate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8bc73-ef72-4040-ad0f-110be4dc6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective=\"binary:logistic\", seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36169c63-58ef-417e-a500-8a05c2ac0183",
   "metadata": {},
   "source": [
    "First model before hyperparameter tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a9a25-d22a-4f64-9b54-4c2f87ec6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds = 10, eval_metric='aucpr', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf36486-5b4f-43f5-abd6-95ef86da70e0",
   "metadata": {},
   "source": [
    "Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0907b-7f12-48dd-a13e-d8e498630975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this cell can take quite a bit to run\n",
    "# param_grid = {'max_depth': [4, 5, 6],\n",
    "#               'learning_rate': [0.1, 0.05, 0.01],\n",
    "#               'gamma': [0, 0.25, 1],\n",
    "#               'reg_lambda': [0, 1.0, 10],\n",
    "#               'scale_pos_weight': [1, 3, 5]}\n",
    "\n",
    "# optimal_params = GridSearchCV(estimator=xgb.XGBClassifier(objective=\"binary:logistic\", seed=42, subsample=0.8, colsample_bytree=0.5),\n",
    "#                              param_grid=param_grid, scoring='roc_auc', verbose=0, n_jobs=-1, cv=5)\n",
    "\n",
    "\n",
    "# optimal_params.fit(X_train, y_train, verbose=False, early_stopping_rounds = 10, eval_metric='auc', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5bcf1a-0e74-44d5-b651-4324e003d377",
   "metadata": {},
   "source": [
    "Extract the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bb138-33e4-45fe-b3a3-32d890e8d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330e49b-716f-42f8-ad7f-c739c6d6cf20",
   "metadata": {},
   "source": [
    "Build the model with our new parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db7ccf-63a4-4eb2-bc18-7c1149be065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective=\"binary:logistic\", seed=42, gamma=0, learning_rate=0.1, max_depth=4, reg_lambda=0, scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87131815-82e9-4fbe-b432-e91f290da540",
   "metadata": {},
   "source": [
    "Train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cdc7b-6757-407d-b626-22e8eeae6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds = 10, eval_metric='aucpr', eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e46d20-ca31-4911-aa9d-7d2fbacce491",
   "metadata": {},
   "source": [
    "Extract the features and their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe377aaa-9849-42cb-a2b5-256622568dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = pd.DataFrame(clf_xgb.feature_importances_, \n",
    "                               index=all_cols, \n",
    "                               columns=['Importance']).sort_values(['Importance'], ascending=False)\n",
    "\n",
    "feat_importance['Index'] = range(feat_importance.shape[0])\n",
    "feat_importance_cut = feat_importance[feat_importance['Importance'] > 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e8ddc-e3a8-46a4-810a-5482ad19b2df",
   "metadata": {},
   "source": [
    "Plot the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c4fc4-7b39-41b6-967c-67a4f6a6d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.pointplot(x='Index', y='Importance', data=feat_importance_cut, linestyles='')\n",
    "plt.xlabel(xlabel='')\n",
    "\n",
    "for i, ind in enumerate(feat_importance_cut.index):\n",
    "    x = feat_importance.loc[ind, 'Index']\n",
    "    y = feat_importance.loc[ind, 'Importance']\n",
    "    plt.text(x+0.08, y, ind, fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1744bf5-9a0f-4208-a7dd-b9e4ceb5c2fb",
   "metadata": {},
   "source": [
    "## 09 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8108629-bda0-4ceb-bf14-53c2ec7dc7b0",
   "metadata": {},
   "source": [
    "While the output of the classification model provided a high accuracy, the labels it used as its source of truth for training and validation came form a completely unsupervised process with a lot of room for improvement. For example, Universal Manifold Approximation and Projection is an excellent algorithm for dimensionality reduction and pure exploratory data analysis. That said, other dimmensionality reduction techniques, such as non-negative factorization matrix or, other clustering algorithms that do not expect the parameter K but that provide noise in place of the wrong assignment of a label, might have been better suited for the gender inference task. Our k-means only achieved a silhouette score of ~67 and this roughly tells us the measure by which our groups are clorely related to themeselves and closely unrelated to the other group(s).\n",
    "\n",
    "Nevertheless, a proof of concept such as the one created for this task can be beneficial for the operations at The Iconic in several ways. For example, while gender was not a clear cut replacement for the source of truth, segmenting consumers based of their purchasing preference, whether based on male or female clothing purchases, or sporty or accessory-full ones, these segments can help tailor marketing strategies more effectively and customize the experience of our customers further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
